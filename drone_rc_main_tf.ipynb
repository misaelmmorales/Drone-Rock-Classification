{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning-based automated rock classification via high-resolution drone-captured core sample imagery\n",
    "***\n",
    "### Domenico M. Crisafulli, Misael M. Morales, and Carlos Torres-Verdin\n",
    "#### The University of Texas at Austin, 2024\n",
    "***\n",
    "\n",
    "## Build and Train NN-classifier\n",
    "| Class             | OLD   | New   |\n",
    "| ---               | ---   | ---   |\n",
    "| Background        | 0     | 0     |\n",
    "| Sandstone type 1  | 1     | 2     |\n",
    "| Shaly Rock        | 2     | 3     |\n",
    "| Sandstone type 2  | 3     | 4     |\n",
    "| Carbonate         | 4     | 5     |\n",
    "| Shale             | 5     | 6     |\n",
    "| Sandstone type 3  | 6     | 7     |\n",
    "| Box               | 10    | 1     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.applications.resnet import ResNet50, preprocess_input\n",
    "\n",
    "def check_tf_gpu():\n",
    "    sys_info = tf.sysconfig.get_build_info()\n",
    "    version, cuda, cudnn = tf.__version__, sys_info[\"cuda_version\"], sys_info[\"cudnn_version\"]\n",
    "    count = len(tf.config.experimental.list_physical_devices())\n",
    "    name  = [device.name for device in tf.config.experimental.list_physical_devices('GPU')]\n",
    "    print('-'*60)\n",
    "    print('----------------------- VERSION INFO -----------------------')\n",
    "    print('TF version: {} | # Device(s) available: {}'.format(version, count))\n",
    "    print('TF Built with CUDA? {} | CUDA: {} | cuDNN: {}'.format(tf.test.is_built_with_cuda(), cuda, cudnn))\n",
    "    print(tf.config.list_physical_devices()[0],'\\n', tf.config.list_physical_devices()[1])\n",
    "    print('-'*60+'\\n')\n",
    "    return None\n",
    "\n",
    "check_tf_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.load('data/x_images.npy')\n",
    "y_data = np.load('data/y_images.npy')\n",
    "print('X: {} | y: {}'.format(X_data.shape, y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    def convolution_block(block_input, num_filters=256, kernel_size=3, dilation_rate=1, use_bias=False):\n",
    "        x = layers.Conv2D(num_filters, kernel_size=kernel_size, dilation_rate=dilation_rate, padding=\"same\", \n",
    "                          use_bias=use_bias, kernel_initializer=keras.initializers.HeNormal())(block_input)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        return x\n",
    "\n",
    "    def DilatedSpatialPyramidPooling(dspp_input):\n",
    "        dims = dspp_input.shape\n",
    "        x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "        x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "        out_pool = layers.UpSampling2D(\n",
    "            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\")(x)\n",
    "        out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "        out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "        out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "        out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "        output = convolution_block(x, kernel_size=1)\n",
    "        return output\n",
    "\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    \n",
    "    preprocessed = preprocess_input(model_input)\n",
    "    resnet50 = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=preprocessed)\n",
    "\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(X_data)), len(X_data), replace=False)\n",
    "n_train = int(len(idx) * 0.77)\n",
    "X_data = np.repeat(X_data, 3, axis=-1)\n",
    "\n",
    "X_train, y_train = X_data[idx[:n_train]], y_data[idx[:n_train]]\n",
    "X_test,  y_test  = X_data[idx[n_train:]], y_data[idx[n_train:]]\n",
    "print('X - train: {} | test: {}'.format(X_train.shape, X_test.shape))\n",
    "print('y - train: {} | test: {}'.format(y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3Plus(image_size=512, num_classes=1)\n",
    "print('# params: {:,}'.format(model.count_params()))\n",
    "model.compile(optimizer=optimizers.AdamW(1e-3, 4e-6), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit = model.fit(X_train, y_train,\n",
    "                batch_size       = 8,\n",
    "                epochs           = 10,\n",
    "                validation_split = 0.2,\n",
    "                shuffle          = True,\n",
    "                verbose          = 1)\n",
    "\n",
    "model.save_weights('rockClassification.weights.h5')\n",
    "pd.DataFrame(fit.history).to_csv('fit_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.read_csv('fit_history.csv')\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(losses.index, losses.accuracy, ls='-', marker='o', label='Accuracy')\n",
    "plt.plot(losses.index, losses.val_accuracy, ls='--', marker='.', label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(facecolor='lightgrey', edgecolor='k')\n",
    "plt.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3Plus(image_size=512, num_classes=1)\n",
    "model.load_weights('rockClassification.weights.h5')\n",
    "print('# params: {:,}'.format(model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train, verbose=0)\n",
    "y_test_pred  = model.predict(X_test, verbose=0).round()\n",
    "print('Pred - train: {} | test: {}'.format(y_train_pred.shape, y_test_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 10, figsize=(15,5), sharex=True, sharey=True)\n",
    "for j in range(10):\n",
    "    ax1, ax2, ax3 = axs[0,j], axs[1,j], axs[2,j]\n",
    "    im1 = ax1.imshow(X_train[j])\n",
    "    im2 = ax2.imshow(y_train[j])\n",
    "    im3 = ax3.imshow(y_train_pred[j])\n",
    "    [a.set(xticks=[], yticks=[]) for a in [ax1, ax2, ax3]]\n",
    "    [plt.colorbar(i, pad=0.04, fraction=0.046) for i in [im1,im2,im3]]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
