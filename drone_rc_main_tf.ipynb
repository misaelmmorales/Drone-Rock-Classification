{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning-based automated rock classification via high-resolution drone-captured core sample imagery\n",
    "***\n",
    "### Domenico M. Crisafulli, Misael M. Morales, and Carlos Torres-Verdin\n",
    "#### The University of Texas at Austin, 2024\n",
    "***\n",
    "\n",
    "## Build and Train NN-classifier\n",
    "| Class             | OLD   | New   |\n",
    "| ---               | ---   | ---   |\n",
    "| Background        | 0     | 0     |\n",
    "| Sandstone type 1  | 1     | 2     |\n",
    "| Shaly Rock        | 2     | 3     |\n",
    "| Sandstone type 2  | 3     | 4     |\n",
    "| Carbonate         | 4     | 5     |\n",
    "| Shale             | 5     | 6     |\n",
    "| Sandstone type 3  | 6     | 7     |\n",
    "| Box               | 10    | 1     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "----------------------- VERSION INFO -----------------------\n",
      "TF version: 2.16.1 | # Device(s) available: 2\n",
      "TF Built with CUDA? True | CUDA: 12.0 | cuDNN: 8\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU') \n",
      " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras import layers, losses, optimizers, activations\n",
    "from keras.applications.resnet import ResNet50, preprocess_input\n",
    "\n",
    "def check_tf_gpu(verbose:bool=True):\n",
    "    sys_info = tf.sysconfig.get_build_info()\n",
    "    version, cuda, cudnn = tf.__version__, sys_info[\"cuda_version\"], sys_info[\"cudnn_version\"]\n",
    "    count = len(tf.config.experimental.list_physical_devices())\n",
    "    name  = [device.name for device in tf.config.experimental.list_physical_devices('GPU')]\n",
    "    if verbose:\n",
    "        print('-'*60)\n",
    "        print('----------------------- VERSION INFO -----------------------')\n",
    "        print('TF version: {} | # Device(s) available: {}'.format(version, count))\n",
    "        print('TF Built with CUDA? {} | CUDA: {} | cuDNN: {}'.format(tf.test.is_built_with_cuda(), cuda, cudnn))\n",
    "        print(tf.config.list_physical_devices()[0],'\\n', tf.config.list_physical_devices()[1])\n",
    "        print('-'*60+'\\n')\n",
    "    return None\n",
    "\n",
    "check_tf_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_image(input_image, patch_h=252, patch_w=252, pad=4, channel_axis=-1):\n",
    "    if channel_axis is not None:\n",
    "        h, w, c = input_image.shape\n",
    "    else:\n",
    "        h, w = input_image.shape\n",
    "    patches = []\n",
    "    for i in range(0, h, patch_h):\n",
    "        for j in range(0, w, patch_w):\n",
    "            if channel_axis is not None:\n",
    "                patch = input_image[i:i+patch_h, j:j+patch_w, :]\n",
    "                patch = np.pad(patch, ((pad,pad),(pad,pad),(0,0)))\n",
    "            else:\n",
    "                patch = input_image[i:i+patch_h, j:j+patch_w]\n",
    "                patch = np.pad(patch, ((pad,pad),(pad,pad)))\n",
    "            patches.append(patch)\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names_pictures = []\n",
    "for root, dirs, files in os.walk('data'):\n",
    "    for f in files:\n",
    "        if (f.endswith('.jpg') or f.endswith('.JPG')) and f.startswith('DJI'):\n",
    "            x_names_pictures.append(os.path.join(root, f))\n",
    "\n",
    "y_names_masks = []\n",
    "for root, dirs, files in os.walk('data'):\n",
    "    for file in files:\n",
    "        if file.endswith('.mat') and file.startswith('img_'):\n",
    "            y_names_masks.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 17/17 [00:17<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3024, 4032, 3) (15, 3024, 4032)\n"
     ]
    }
   ],
   "source": [
    "x_pictures = []\n",
    "y_masks    = []\n",
    "for i in tqdm(range(len(x_names_pictures)), desc='Loading images'):\n",
    "    y = sio.loadmat(y_names_masks[i],simplify_cells=True)\n",
    "    if 'AA' in y.keys():\n",
    "        y_masks.append(y['AA'])\n",
    "        x = np.array(Image.open(x_names_pictures[i]).convert('RGB'))\n",
    "        x_pictures.append(x)\n",
    "\n",
    "X_data = np.array(x_pictures)\n",
    "y_data = np.array(y_masks)\n",
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patching images: 100%|██████████| 15/15 [00:00<00:00, 66.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 512, 512, 3) (720, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 504\n",
    "PADDING = 4\n",
    "PADDED_IMAGE = IMAGE_SIZE+PADDING*2\n",
    "\n",
    "x_data_patched = []\n",
    "y_data_patched = []\n",
    "for i in tqdm(range(X_data.shape[0]), desc='Patching images'):\n",
    "    x = patch_image(X_data[i], patch_h=IMAGE_SIZE, patch_w=IMAGE_SIZE, pad=PADDING)\n",
    "    x_data_patched.append(x)\n",
    "    y = patch_image(y_data[i], patch_h=IMAGE_SIZE, patch_w=IMAGE_SIZE, pad=PADDING, channel_axis=None)\n",
    "    y_data_patched.append(y)\n",
    "    \n",
    "x_data_patched = np.array(x_data_patched).reshape(-1, PADDED_IMAGE, PADDED_IMAGE, 3)\n",
    "y_data_patched = np.array(y_data_patched).reshape(-1, PADDED_IMAGE, PADDED_IMAGE, 1)\n",
    "print(x_data_patched.shape, y_data_patched.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nonzero Filter: 100%|██████████| 720/720 [00:00<00:00, 10326.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(273, 512, 512, 3) (273, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "idx = []\n",
    "for i in tqdm(range(y_data_patched.shape[0]), desc='Nonzero Filter'):\n",
    "    m = y_data_patched[i]\n",
    "    p = np.sum(m)\n",
    "    if p > 10000:\n",
    "        idx.append(i)\n",
    "\n",
    "x_data_nonzero = x_data_patched[idx].astype(np.float32)\n",
    "y_data_nonzero = y_data_patched[idx].astype(np.float32)\n",
    "print(x_data_nonzero.shape, y_data_nonzero.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X - train: (250, 512, 512, 3) | test: (23, 512, 512, 3)\n",
      "y - train: (250, 512, 512, 1) | test: (23, 512, 512, 1)\n",
      "Labels - train: [0. 1. 2. 3. 4. 5. 6.] | test: [0. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "rand_idx = np.random.choice(x_data_nonzero.shape[0], size=x_data_nonzero.shape[0], replace=False)\n",
    "n_train = 250\n",
    "\n",
    "X_train = x_data_nonzero[rand_idx[:n_train]]/255\n",
    "y_train = y_data_nonzero[rand_idx[:n_train]]\n",
    "\n",
    "X_test = x_data_nonzero[rand_idx[n_train:]]/255\n",
    "y_test = y_data_nonzero[rand_idx[n_train:]]\n",
    "\n",
    "y_train[y_train==255] = 5\n",
    "y_test[y_test==255] = 5\n",
    "\n",
    "print('X - train: {} | test: {}'.format(X_train.shape, X_test.shape))\n",
    "print('y - train: {} | test: {}'.format(y_train.shape, y_test.shape))\n",
    "print('Labels - train: {} | test: {}'.format(np.unique(y_train), np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 15, figsize=(25,4), sharex=True, sharey=True)\n",
    "for j in range(15):\n",
    "    ax1, ax2 = axs[0,j], axs[1,j]\n",
    "    ax1.imshow(X_train[j])\n",
    "    ax2.imshow(y_train[j])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoreSegNet(image_size:int=512, in_channels:int=3, out_channels:int=1):\n",
    "    \n",
    "    def convolution_block(inp, num_filters, kernel_size=3):\n",
    "        _ = layers.Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(inp)\n",
    "        _ = layers.BatchNormalization()(_)\n",
    "        _ = activations.relu(_)\n",
    "        return _\n",
    "    \n",
    "    # Encoder\n",
    "    input = layers.Input(shape=(image_size, image_size, in_channels))\n",
    "    x = convolution_block(input, 16)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    f1 = x\n",
    "    x = convolution_block(x, 64)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    f2 = x\n",
    "    x = convolution_block(x, 256)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    f3 = x\n",
    "    \n",
    "    # Decoder\n",
    "    x = layers.concatenate([x, f3])\n",
    "    x = convolution_block(x, 256)\n",
    "    x = layers.Conv2DTranspose(64, 2, 2, padding='same')(x)\n",
    "\n",
    "    x = layers.concatenate([x, f2])\n",
    "    x = convolution_block(x, 64)\n",
    "    x = layers.Conv2DTranspose(16, 2, 2, padding='same')(x)\n",
    "\n",
    "    x = layers.concatenate([x, f1])\n",
    "    x = convolution_block(x, 16)\n",
    "    x = layers.Conv2DTranspose(out_channels, 2, 2, padding='same')(x)\n",
    "\n",
    "    output = layers.Conv2D(out_channels, 1, 1)(x)\n",
    "    output = layers.Activation('softmax')(output)\n",
    "    \n",
    "    return Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonitorCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, monitor:int=10):\n",
    "        super(MonitorCallback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch+1) % self.monitor == 0:\n",
    "            print('Epoch: {} | Accuracy: {:.3f} | Loss: {:.5f}'.format(epoch+1, logs['accuracy'], logs['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters: 1,488,592\n",
      "Epoch: 10 | Loss: -0.92593\n",
      "Epoch: 20 | Loss: -0.92600\n",
      "Epoch: 30 | Loss: -0.92600\n",
      "Epoch: 40 | Loss: -0.92600\n",
      "Epoch: 50 | Loss: -0.92600\n",
      "Epoch: 60 | Loss: -0.92598\n",
      "Epoch: 70 | Loss: -0.92600\n",
      "Epoch: 80 | Loss: -0.92600\n"
     ]
    }
   ],
   "source": [
    "model = CoreSegNet(image_size=512, out_channels=6)\n",
    "print('# parameters: {:,}'.format(model.count_params()))\n",
    "\n",
    "optimizer = optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-6)\n",
    "criterion = losses.MeanSquaredError()\n",
    "callbacks = [MonitorCallback(monitor=10)]\n",
    "model.compile(optimizer=optimizer, loss=criterion, metrics=['accuracy', 'mse'])\n",
    "\n",
    "start = time()\n",
    "fit = model.fit(X_train, y_train,\n",
    "                batch_size       = 8, \n",
    "                epochs           = 50, \n",
    "                validation_split = 0.2,\n",
    "                shuffle          = True,\n",
    "                verbose          = 0,\n",
    "                callbacks        = [callbacks])\n",
    "print('-'*30+'\\n'+'Training time: {:.2f} minutes'.format((time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(fit.history['loss'], ls='--', label='train loss')\n",
    "ax1.plot(fit.history['val_loss'], ls='--', label='val loss')\n",
    "ax2.plot(fit.history['accuracy'], label='train accuracy', color='red')\n",
    "ax2.plot(fit.history['val_accuracy'], label='val accuracy', color='green')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax1.grid(True, which='both')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train[:15], verbose=0)\n",
    "y_test_pred  = model.predict(X_test[:15], verbose=0)\n",
    "print('Pred - train: {} | test: {}'.format(y_train_pred.shape, y_test_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 15, figsize=(20,5), sharex=True, sharey=True)\n",
    "for j in range(15):\n",
    "    ax1, ax2, ax3 = axs[0,j], axs[1,j], axs[2,j]\n",
    "    ax1.imshow(X_train[j])\n",
    "    ax2.imshow(y_train[j])\n",
    "    ax3.imshow(y_train_pred[j])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.load('data/x_images.npy')\n",
    "y_data = np.load('data/y_images.npy')\n",
    "print('X: {} | y: {}'.format(X_data.shape, y_data.shape))\n",
    "\n",
    "idx = np.random.choice(range(len(X_data)), len(X_data), replace=False)\n",
    "n_train = int(len(idx) * 0.8)\n",
    "\n",
    "X_train, y_train = X_data[idx[:n_train]], y_data[idx[:n_train]]\n",
    "X_test,  y_test  = X_data[idx[n_train:]], y_data[idx[n_train:]]\n",
    "print('X - train: {} | test: {}'.format(X_train.shape, X_test.shape))\n",
    "print('y - train: {} | test: {}'.format(y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RockClassification()\n",
    "print('# params: {:,}'.format(model.count_params()))\n",
    "model.compile(optimizer=optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit = model.fit(X_train, y_train,\n",
    "                batch_size       = 4,\n",
    "                epochs           = 10,\n",
    "                validation_split = 0.2,\n",
    "                shuffle          = True,\n",
    "                verbose          = 1)\n",
    "\n",
    "model.save_weights('rockClassification.weights.h5')\n",
    "pd.DataFrame(fit.history).to_csv('fit_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3Plus(image_size=512, num_classes=1)\n",
    "print('# params: {:,}'.format(model.count_params()))\n",
    "model.compile(optimizer=optimizers.AdamW(1e-3, 4e-6), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit = model.fit(X_train, y_train,\n",
    "                batch_size       = 8,\n",
    "                epochs           = 10,\n",
    "                validation_split = 0.2,\n",
    "                shuffle          = True,\n",
    "                verbose          = 1)\n",
    "\n",
    "model.save_weights('DeeplabV3Plus.weights.h5')\n",
    "pd.DataFrame(fit.history).to_csv('DeeplabV3Plus_fit_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RockClassification()\n",
    "model.load_weights('rockClassification.weights.h5')\n",
    "print('# params: {:,}'.format(model.count_params()))\n",
    "\n",
    "losses = pd.read_csv('fit_history.csv')\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(losses.index, losses.accuracy, ls='-', marker='o', label='Accuracy')\n",
    "plt.plot(losses.index, losses.val_accuracy, ls='--', marker='.', label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(facecolor='lightgrey', edgecolor='k')\n",
    "plt.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeplabV3Plus(image_size=512, num_classes=1)\n",
    "model.load_weights('DeeplabV3Plus.weights.h5')\n",
    "print('# params: {:,}'.format(model.count_params()))\n",
    "\n",
    "losses = pd.read_csv('DeeplabV3Plus_fit_history.csv')\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(losses.index, losses.accuracy, ls='-', marker='o', label='Accuracy')\n",
    "plt.plot(losses.index, losses.val_accuracy, ls='--', marker='.', label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(facecolor='lightgrey', edgecolor='k')\n",
    "plt.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train[:6], verbose=0).round()\n",
    "y_test_pred  = model.predict(X_test[:6], verbose=0).round()\n",
    "print('Pred - train: {} | test: {}'.format(y_train_pred.shape, y_test_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 6, figsize=(15,5), sharex=True, sharey=True)\n",
    "for j in range(6):\n",
    "    ax1, ax2, ax3 = axs[0,j], axs[1,j], axs[2,j]\n",
    "    im1 = ax1.imshow(X_train[j])\n",
    "    im2 = ax2.imshow(y_train[j])\n",
    "    im3 = ax3.imshow(y_train_pred[j])\n",
    "    [a.set(xticks=[], yticks=[]) for a in [ax1, ax2, ax3]]\n",
    "    [plt.colorbar(i, pad=0.04, fraction=0.046) for i in [im1,im2,im3]]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
